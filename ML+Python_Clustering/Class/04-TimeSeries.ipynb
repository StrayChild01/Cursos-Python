{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "\n",
    "This section will walk through simple time series analysis, and forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 538 ms, total: 3.19 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Resampling data from minute interval to day\n",
    "bit_df = pd.read_csv('../data/coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv')\n",
    "# Convert unix time to datetime\n",
    "bit_df['date'] = pd.to_datetime(bit_df.Timestamp, unit='s')\n",
    "# Reset index\n",
    "bit_df = bit_df.set_index('date')\n",
    "# Rename columns so easier to code\n",
    "bit_df = bit_df.rename(columns={'Open':'open', 'High': 'hi', 'Low': 'lo', \n",
    "                       'Close': 'close', 'Volume_(BTC)': 'vol_btc',\n",
    "                       'Volume_(Currency)': 'vol_cur', \n",
    "                       'Weighted_Price': 'wp', 'Timestamp': 'ts'})\n",
    "# Resample and only use recent samples that aren't missing\n",
    "bit_df = bit_df.resample('d').agg({'open': 'first', 'hi': 'max', \n",
    "    'lo': 'min', 'close': 'last', 'vol_btc': 'sum',\n",
    "    'vol_cur': 'sum', 'wp': 'mean', 'ts': 'min'}).iloc[-1000:]\n",
    "# drop last row as it is not complete\n",
    "bit_df = bit_df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs ds and y columns\n",
    "ts = (bit_df\n",
    "    .reset_index()\n",
    "    .rename(columns={'date': 'ds', 'close': 'y'})\n",
    "[['ds', 'y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts.set_index('ds').plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(daily_seasonality=True)\n",
    "m.fit(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a future object and predict into it\n",
    "future = m.make_future_dataframe(periods=24)\n",
    "forecast = m.predict(future)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction, include the uncertainty lines\n",
    "ax = m.plot(forecast, uncertainty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the trend, yearly, weekly and daily componentsb\n",
    "ax = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Snow Data\n",
    "\n",
    "* Use prophet to predict 100 days in the future of Snow Depth (SNWD) \n",
    "* What month has the most snow\n",
    "\n",
    "Data from https://www.ncdc.noaa.gov/cdo-web/search\n",
    "\n",
    "Data at ``../data/snow-alta-1990-2017.csv``\n",
    "\n",
    "Documentation - https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf\n",
    "\n",
    "\n",
    "* STATION_NAME (max 50 characters) is the (usually city/airport name). Optional\n",
    "output field.\n",
    "* STATION - 17 characters) is the station identification code. Please see\n",
    "http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
    "* NAME - name of the station\n",
    "* LATITUDE\n",
    "* LONGITUDE\n",
    "* ELEVATION - meters\n",
    "* DATE - YYYY-MM-DD\n",
    "* DAPR - Number of days included in the multiday precipitation total (MDPR)\n",
    "* DAPR_ATTRIBUTES\n",
    "* DASF - Number of days included in the multiday snowfall total (MDSF)\n",
    "* DASF_ATTRIBUTES \n",
    "* MDPR -  Multiday precipitation total (mm or inches as per user preference; use with DAPR and DWPR, if\n",
    "available)\n",
    "* MDPR_ATTRIBUTES\n",
    "* MDSF - Multiday snowfall total (mm or inches as per user preference)\n",
    "* MDSF_ATTRIBUTES\n",
    "* PRCP - Precipitation (mm or inches as per user preference, inches to hundredths on Daily Form pdf file)\n",
    "* PRCP_ATTRIBUTES \n",
    "* SNOW -  Snowfall (mm or inches as per user preference, inches to tenths on Daily Form pdf file)\n",
    "* SNOW_ATTRIBUTES\n",
    "* SNWD -  Snow depth (mm or inches as per user preference, inches on Daily Form pdf file)\n",
    "* SNWD_ATTRIBUTES\n",
    "* TMAX - Maximum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on\n",
    "Daily Form pdf file\n",
    "* TMAX_ATTRIBUTES \n",
    "* TMIN - Minimum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on\n",
    "Daily Form pdf file\n",
    "* TMIN_ATTRIBUTES\n",
    "* TOBS - Temperature at the time of observation (Fahrenheit or Celsius as per user preference)\n",
    "* TOBS_ATTRIBUTES\n",
    "* WT01 - Fog, ice fog, or freezing fog (may include heavy fog)\n",
    "* WT01_ATTRIBUTES\n",
    "* WT03 - Thunder\n",
    "* WT03_ATTRIBUTES\n",
    "* WT04 - Ice pellets, sleet, snow pellets, or small hail\n",
    "* WT04_ATTRIBUTES\n",
    "* WT05 -  Hail (may include small hail)\n",
    "* WT05_ATTRIBUTES\n",
    "* WT06 - Glaze or rime\n",
    "* WT06_ATTRIBUTES\n",
    "* WT11 -  High or damaging winds\n",
    "* WT11_ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using log of data\n",
    "\n",
    "Prediction may work better if we tweak the data. In this case let's try taking the log of the bitcoin price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = ts.assign(y=lambda x: np.log(x.y))\n",
    "ts2.set_index('ds').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Prophet() #dont need daily_seasonality=True)\n",
    "m2.fit(ts2)\n",
    "future2 = m2.make_future_dataframe(periods=24)\n",
    "forecast2 = m2.predict(future2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction, include the uncertainty lines\n",
    "ax = m2.plot(forecast2, uncertainty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = m2.plot_components(forecast2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Log of Time Series\n",
    "\n",
    "* Run the snow calculation using the log of the snow depth. Does it track better? (Hint: might need to add 1 before logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
