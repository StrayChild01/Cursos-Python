{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this Notebook we will examine bitcoin data and see if we can predict a buy or sell.\n",
    "\n",
    "https://www.kaggle.com/mczielinski/bitcoin-historical-data/data\n",
    "\n",
    "Data under CC BY-SA 4.0 License\n",
    "\n",
    "https://www.kaggle.com/mczielinski/bitcoin-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, model_selection, preprocessing, tree\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ClassificationReport, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Resampling data from minute interval to day\n",
    "bit_df = pd.read_csv('../data/coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv')\n",
    "# Convert unix time to datetime\n",
    "bit_df['date'] = pd.to_datetime(bit_df.Timestamp, unit='s')\n",
    "# Reset index\n",
    "bit_df = bit_df.set_index('date')\n",
    "# Rename columns so easier to code\n",
    "bit_df = bit_df.rename(columns={'Open':'open', 'High': 'hi', 'Low': 'lo', \n",
    "                       'Close': 'close', 'Volume_(BTC)': 'vol_btc',\n",
    "                       'Volume_(Currency)': 'vol_cur', \n",
    "                       'Weighted_Price': 'wp', 'Timestamp': 'ts'})\n",
    "# Resample and only use recent samples that aren't missing\n",
    "bit_df = bit_df.resample('d').agg({'open': 'first', 'hi': 'max', \n",
    "    'lo': 'min', 'close': 'last', 'vol_btc': 'sum',\n",
    "    'vol_cur': 'sum', 'wp': 'mean', 'ts': 'min'}).iloc[-1000:]\n",
    "bit_df['buy'] = (bit_df.close.shift(-1) > bit_df.close).astype(int)\n",
    "# drop last row as it is not complete\n",
    "bit_df = bit_df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Load Data\n",
    "\n",
    "* Load the mushroom data (hint use ``pd.get_dummies``)\n",
    "\n",
    "Mushroom data https://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "data in ``../data/agaricus-lepiota.data.txt``\n",
    "\n",
    "First column is class: edible=e, poisonous=p\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s \n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s \n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y \n",
    "4. bruises?: bruises=t,no=f \n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s \n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n \n",
    "7. gill-spacing: close=c,crowded=w,distant=d \n",
    "8. gill-size: broad=b,narrow=n \n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y \n",
    "10. stalk-shape: enlarging=e,tapering=t \n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=? \n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "16. veil-type: partial=p,universal=u \n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y \n",
    "18. ring-number: none=n,one=o,two=t \n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z \n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y \n",
    "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y \n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "* The process of training classifier is to get X and y and call ``.fit``.\n",
    "* To predict values of y (y hat), call ``.predict(X)``\n",
    "* To get the accuracy call ``.score(X, y)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = {'buy'}\n",
    "cols = [c for c in bit_df.columns if c not in ignore]\n",
    "X = bit_df[cols]\n",
    "y = bit_df.buy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = tree.DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "dt_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this goes to a Unix path\n",
    "tree.export_graphviz(dt_model, out_file='/tmp/tree1.dot', \n",
    "                     feature_names=X.columns, class_names=['Sell', 'Buy'],\n",
    "                    filled=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# This doesn't run on Windows. Also requires that you have graphviz installed (not a Python module)\n",
    "dot -Tpng -o../img/tree1.png /tmp/tree1.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Big Tree](../img/tree1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.score(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(zip(X.columns, dt_model.feature_importances_), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Predict Mushroom Poisonous\n",
    "\n",
    "* Create a decision tree to model whether a mushroom is poisonous. What is the score?\n",
    "* What are the most important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try and Generalize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = {'buy'}\n",
    "cols = [c for c in bit_df.columns if c not in ignore]\n",
    "X = bit_df[cols]\n",
    "y = bit_df.buy\n",
    "X_train, X_test, y_train, y_test = model_selection.\\\n",
    "    train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = tree.DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "dt2.fit(X_train, y_train)\n",
    "dt2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(dt2, out_file='/tmp/tree2.dot', \n",
    "                     feature_names=X.columns, class_names=['Sell', 'Buy'],\n",
    "                    filled=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dot -Tpng -o../img/tree2.png /tmp/tree2.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Big Tree](../img/tree2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Decision Tree\n",
    "\n",
    "* Create a testing and training set \n",
    "* Check if the model generalizes to the testing set\n",
    "* Visualize the tree (if you have graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "We need to be a little more intelligent about what we are basing our decisions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(df, num_periods=14):\n",
    "    \"\"\"Relative strength index\"\"\"\n",
    "    prev = df.close.shift(1)\n",
    "    change = (df.close - prev) / prev\n",
    "    change = change.rolling(window=num_periods).mean().fillna(0)\n",
    "    up, down = change.copy(), change.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    up2 = up.rolling(center=False, window=num_periods).mean()\n",
    "    down2 = down.rolling(center=False, window=num_periods).mean()\n",
    "    rs = (up2 / down2).fillna(0)\n",
    "    res = (100 - 100/(1 + rs))\n",
    "    return res.replace([np.inf], 0)\n",
    "\n",
    "def stoc(df, num_periods=14):\n",
    "    \"\"\"Stochastic Oscillator\"\"\"\n",
    "    cur = df.close\n",
    "    low = df.close.rolling(center=False, window=num_periods).min() \n",
    "    high = df.close.rolling(center=False, window=num_periods).max() \n",
    "    return (100 * (cur - low)/(high - low)).fillna(0)\n",
    "\n",
    "def williams(df, num_periods=14):\n",
    "    \"\"\"\n",
    "    Williams %R ranges from -100 to 0. When its value is above -20, it indicates a sell signal\n",
    "and when its value is below -80, it indicates a buy signal.\n",
    "    \"\"\"\n",
    "    cur = df.close#.iloc[-1]\n",
    "    low = df.close.rolling(center=False, window=num_periods).min() #shift(-num_periods) .iloc[-num_periods:].min()\n",
    "    high = df.close.rolling(center=False, window=num_periods).max() #df.close.iloc[-num_periods:].max()\n",
    "    return (-100 * (high - cur) / (high - low)).fillna(-50)\n",
    "\n",
    "def proc(df, num_periods=14):\n",
    "    \"\"\"It measures the most recent change in price with respect to the price in n days ago.\n",
    "    https://www.investopedia.com/terms/p/pricerateofchange.asp\n",
    "    \"\"\"\n",
    "    cur = df.close\n",
    "    prev = df.close.shift(-num_periods)\n",
    "    return ((cur - prev)/(prev*100)).fillna(0)\n",
    "\n",
    "def obv(df, vol='vol_btc'):\n",
    "    \"\"\"\n",
    "    On balance volume - Use volume flow to predict changes\n",
    "\n",
    "    if close up add vol, if down subtract\n",
    "    \"\"\"\n",
    "    # -1 if down 1 if up\n",
    "    close_up_or_down = (bit_df.close.diff().le(0) * 2 - 1) \n",
    "    obv = (close_up_or_down * bit_df[vol]).cumsum()\n",
    "    return obv.fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for func in [rsi, \n",
    "             stoc, williams, proc, obv]:\n",
    "    bit_df[func.__name__] = func(bit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = {'buy'}\n",
    "cols2 = [c for c in bit_df.columns if c not in ignore]\n",
    "X = bit_df[cols2]\n",
    "y = bit_df.buy\n",
    "X_train, X_test, y_train, y_test = model_selection.\\\n",
    "    train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3 = tree.DecisionTreeClassifier(random_state=42, max_depth=7)\n",
    "dt3.fit(X_train, y_train)\n",
    "dt3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(zip(X.columns, dt3.feature_importances_), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = ensemble.RandomForestClassifier(random_state=3)#, max_depth=7)\n",
    "rf1.fit(X_train, y_train)\n",
    "rf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Feature Engineering\n",
    "\n",
    "The (wheat) seed dataset has a feature engineered column, compactness\n",
    "\\begin{align}\n",
    "C=4*pi*area/perimeter^2\n",
    "\\end{align}\n",
    "\n",
    "* Does the classification score improve if this column is included?\n",
    "\n",
    "The file is at ``../data/seeds_dataset.txt``\n",
    "\n",
    "\n",
    "It has the following fields:\n",
    "\n",
    "1. area A, \n",
    "2. perimeter P, \n",
    "3. compactness C = 4*pi*A/P^2, \n",
    "4. length of kernel, \n",
    "5. width of kernel, \n",
    "6. asymmetry coefficient \n",
    "7. length of kernel groove. \n",
    "8. variety (Kama, Rosa, Canadian)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/seeds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "\n",
    "def fig_with_title(ax, title, figkwargs):\n",
    "    if figkwargs is None:\n",
    "        figkwargs = {}\n",
    "    if not ax:\n",
    "        fig = plt.figure(**figkwargs)\n",
    "        ax = plt.subplot(111)\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_roc_curve_binary(clf, X, y, label='ROC Curve (area={area:.3})',\n",
    "                          title=\"ROC Curve\", pos_label=None, sample_weight=None,\n",
    "                          ax=None, figkwargs=None):\n",
    "    ax = ax or plt.subplot(111)\n",
    "    ax.set_xlim([-.1, 1])\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    y_score = clf.predict_proba(X)\n",
    "    if y_score.shape[1] != 2 and not pos_label:\n",
    "        warnings.warn(\"Shape is not binary {} and no pos_label\".format(y_score.shape))\n",
    "        return\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_score[:,1], pos_label=pos_label,\n",
    "                                     sample_weight=sample_weight)\n",
    "    except ValueError as e:\n",
    "        if 'is not binary' in str(e):\n",
    "            warnings.warn(\"Check if y is numeric\")\n",
    "            raise\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig, ax = fig_with_title(ax, title, figkwargs)\n",
    "\n",
    "    ax.plot(fpr, tpr, label=label.format(area=roc_auc))\n",
    "    ax.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Guessing')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_binary(rf1, X_test, y_test, figkwargs={'figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellowbrick version\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "roc_viz = ROCAUC(rf1)\n",
    "roc_viz.score(X_test, y_test)\n",
    "roc_viz.poof()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - ROC Curve\n",
    "\n",
    "Print the ROC curve for the seed classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve_multilabels(clf, X, y, labels, label_nums, label='ROC Curve {label} (area={area:.3})',\n",
    "                          title=\"ROC Curve\", sample_weight=None,\n",
    "                               ax=None, figkwargs=None, add_avg=True):\n",
    "    y_bin = preprocessing.label_binarize(y, label_nums)\n",
    "    y_score = clf.predict_proba(X)\n",
    "    fprs = {}\n",
    "    tprs = {}\n",
    "    roc_aucs = {}\n",
    "    for i, l in enumerate(labels):\n",
    "        try:\n",
    "            fprs[i], tprs[i], _ = roc_curve(y_bin[:,i], y_score[:,i],\n",
    "                                          sample_weight=sample_weight)\n",
    "            roc_aucs[i] = auc(fprs[i], tprs[i])\n",
    "        except ValueError as e:\n",
    "            if 'is not binary' in str(e):\n",
    "                warnings.warn(\"Check if y is numeric\")\n",
    "                raise\n",
    "    fig, ax = fig_with_title(ax, title, figkwargs)\n",
    "    for i, l in enumerate(labels):\n",
    "        x = fprs[i]\n",
    "        y = tprs[i]\n",
    "        text=label.format(area=roc_aucs[i], label=l)\n",
    "        ax.plot(x, y, label=text)\n",
    "    if add_avg:\n",
    "        f, t, _ = roc_curve(y_bin.ravel(), y_score.ravel())\n",
    "        r = auc(f, t)\n",
    "        text=label.format(area=r, label='Average')\n",
    "        ax.plot(f, t, label=text, color='k', linewidth=2)\n",
    "    ax.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Guessing')\n",
    "    ax.set_xlim([-.1, 1])\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A Confusion Matrix is another way to evaluate performance. You can see where false positives (lower left) and false negatives (upper right) are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(clf, X, y, labels, random_state=42, annotate=True,\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          title=\"Confusion Matrix\", ax=None, figkwargs=None):\n",
    "    fig, ax = fig_with_title(ax, title, figkwargs)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    fig.colorbar(im)\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    if annotate:\n",
    "        for x in range(len(labels)):\n",
    "            for y in range(len(labels)):\n",
    "                plt.annotate(str(cm[x][y]),\n",
    "                             xy=(y,x),\n",
    "                             ha='center',va='center',color='red', fontsize=25, fontstyle='oblique')\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf1, X_test, y_test, ['sell', 'buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the training set performs much better!\n",
    "plot_confusion_matrix(rf1, X_train, y_train, ['sell', 'buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellowbrick - Using percent\n",
    "mapping = {0:'sell', 1:'buy'}\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm_viz = ConfusionMatrix(rf1, classes=['sell', 'buy'], label_encoder=mapping)\n",
    "cm_viz.score(X_test, y_test)\n",
    "cm_viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellowbrick - Using count\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm_viz = ConfusionMatrix(rf1, classes=['sell', 'buy'], label_encoder=mapping)\n",
    "cm_viz.score(X_test, y_test, percent=False)\n",
    "cm_viz.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Confustion Matrix\n",
    "\n",
    "* Plot a confusion matrix for the seed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "* Precision - Correct positive over all positive - True positives / (false + true positives) - How many selected items are relevant?\n",
    "* Recall - Correct positive over positive that should have been returned - True positives / (true postives + false negatives) - How many relevant items are selected?\n",
    "* F1 - Harmonic mean of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_viz = ClassificationReport(rf1, classes=['buy', 'sell'])\n",
    "cr_viz.score(X_test, y_test)\n",
    "cr_viz.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Create a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Curve\n",
    "from http://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html\n",
    "\n",
    "and \n",
    "https://jmetzen.github.io/2015-04-14/calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "\n",
    "\n",
    "def plot_calibration_curve(est, name, fig_index,                      \n",
    "    X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Plot calibration curve for est w/o and with calibration. \"\"\"\n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv=2, method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv=2, method='sigmoid')\n",
    "\n",
    "    # Logistic regression with no calibration as baseline\n",
    "    lr = LogisticRegression(C=1., solver='lbfgs')\n",
    "\n",
    "    fig = plt.figure(fig_index, figsize=(10, 10))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    for clf, name in [(lr, 'Logistic'),\n",
    "                      (est, name),\n",
    "                      (isotonic, name + ' + Isotonic'),\n",
    "                      (sigmoid, name + ' + Sigmoid')]:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "        else:  # use decision function\n",
    "            prob_pos = clf.decision_function(X_test)\n",
    "            prob_pos = \\\n",
    "                (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "        clf_score = brier_score_loss(y_test, prob_pos, pos_label=y.max())\n",
    "        print(\"%s:\" % name)\n",
    "        print(\"\\tBrier: %1.3f\" % (clf_score))\n",
    "        print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "        print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "        print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred))\n",
    "        print(\"\\tScore: %1.3f\\n\" % clf.score(X_test, y_test))\n",
    "\n",
    "        fraction_of_positives, mean_predicted_value = \\\n",
    "            calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "        ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                 label=\"%s (%1.3f)\" % (name, clf_score))\n",
    "\n",
    "        ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "                 histtype=\"step\", lw=2)\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of positives\")\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "    ax2.set_xlabel(\"Mean predicted value\")\n",
    "    ax2.set_ylabel(\"Count\")\n",
    "    ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "plot_calibration_curve(rf1, 'Random Forest', 1,\n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Models\n",
    "\n",
    "Models have *hyperparameters* that we can tune. Grid search cross validation will hold out some of the data for testing purposes, so we can pass in the full X and y into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf4 = ensemble.RandomForestClassifier()\n",
    "params = {'max_features': [.4, 'auto'],\n",
    "         'n_estimators': [15, 200, 500],\n",
    "         'min_samples_leaf': [1, .1],\n",
    "         'random_state':[42]}\n",
    "cv = model_selection.GridSearchCV(rf4, params).fit(X, y)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5 = ensemble.RandomForestClassifier(**cv.best_params_)\n",
    "rf5.fit(X_train, y_train)\n",
    "rf5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf6 = ensemble.RandomForestClassifier(random_state=41)\n",
    "rf6.fit(X_train, y_train)\n",
    "rf6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves: Do we have enough data?\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                       fig_opts=None):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    fig_opts = fig_opts or {}\n",
    "    plt.figure(**fig_opts)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = model_selection.learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(rf6, 'Random Forest', X, y, fig_opts={'figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_data(filename, resample='d', size=1000):\n",
    "    bit_df = pd.read_csv(filename)\n",
    "    # Convert unix time to datetime\n",
    "    bit_df['date'] = pd.to_datetime(bit_df.Timestamp, unit='s')\n",
    "    # Reset index\n",
    "    bit_df = bit_df.set_index('date')\n",
    "    # Rename columns so easier to code\n",
    "    bit_df = bit_df.rename(columns={'Open':'open', 'High': 'hi', 'Low': 'lo', \n",
    "                           'Close': 'close', 'Volume_(BTC)': 'vol_btc',\n",
    "                           'Volume_(Currency)': 'vol_cur', \n",
    "                           'Weighted_Price': 'wp', 'Timestamp': 'ts'})\n",
    "    # Resample and only use recent samples that aren't missing\n",
    "    bit_df = bit_df.resample(resample).agg({'open': 'first', 'hi': 'mean', \n",
    "        'lo': 'mean', 'close': 'last', 'vol_btc': 'sum',\n",
    "        'vol_cur': 'sum', 'wp': 'mean', 'ts': 'min'})\n",
    "    \n",
    "    # drop if open is missing - ADDED!\n",
    "    bit_df = bit_df[~bit_df.open.isnull()]\n",
    "\n",
    "    if size:\n",
    "        bit_df = bit_df.iloc[-size:]\n",
    "    bit_df['buy'] = (bit_df.close.shift(-1) > bit_df.close).astype(int)\n",
    "    # drop last row as it is not complete\n",
    "    bit_df = bit_df.iloc[:-1]\n",
    "    return bit_df\n",
    "\n",
    "hour_df = get_data('../data/coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv', \n",
    "                   resample='h', size=None)\n",
    "print(hour_df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train(df):\n",
    "    for func in [rsi, \n",
    "             stoc, williams, proc, obv]:\n",
    "        df[func.__name__] = func(df)\n",
    "    \n",
    "    ignore = {'buy'}\n",
    "    cols2 = [c for c in df.columns if c not in ignore]\n",
    "    X = df[cols2]\n",
    "    X = X.fillna(0)\n",
    "    y = df.buy\n",
    "    X_train, X_test, y_train, y_test = model_selection.\\\n",
    "        train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "hX_train, hX_test, hy_train, hy_test = get_test_train(hour_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hX_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(ensemble.RandomForestClassifier(), \n",
    "                    'Random Forest', hX_train, hy_train, fig_opts={'figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Learning Curves\n",
    "* Run a learning curve against the seed data? How much data do we need to train on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
