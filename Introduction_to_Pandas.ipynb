{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore, Visualize, and Predict using Pandas & Jupyter\n",
    "\n",
    "### Learn to import, explore, and tweak your data\n",
    "\n",
    "Matt Harrison (@\\_\\_mharrison\\_\\_)\n",
    "\n",
    "The pandas library is very popular among data scientists, quants, Excel junkies, and Python developers because it allows you to perform data ingestion, exporting, transformation, and visualization with ease. But if you are only familiar with Python, pandas may present some challenges. Since pandas is inspired by Numpy, its syntax conventions can be confusing to Python developers.\n",
    "\n",
    "If you have questions on Python syntax, check out https://github.com/mattharrison/Tiny-Python-3.6-Notebook\n",
    "\n",
    "Much of this content is based on my Pandas book, [*Learning the Pandas Library*](https://www.amazon.com/Learning-Pandas-Library-Munging-Analysis/dp/153359824X/ref=sr_1_3?ie=UTF8&qid=1505448275&sr=8-3&keywords=python+pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Intro\n",
    "\n",
    "Jupyter notebook is an environment for combining interactive coding and text in a webbrowser. This allows us to easily share code as well as narrative around that code. An example that was popular in the scientific community was [the discovery of gravitational waves.](https://losc.ligo.org/s/events/GW150914/GW150914_tutorial.html)\n",
    "\n",
    "The name Jupyter is a rebranding of an open source project previously known as iPython Notebook. The rebranding was to emphasize that although the backend is written in Python, it supports various *kernals* to run other languages, including Julia (the \"Ju\" portion), Python (\"pyt\"), and R (\"er\"). All popular *data science* programming languages.\n",
    "\n",
    "The architecture of Jupyter includes a server running various kernals. Using a *notebook* we can interact with a kernal. Typically we use a webbrowser to do this, but there are other iterfaces, such as an emacs mode (ein).\n",
    "\n",
    "## Using Jupyter\n",
    "\n",
    "After we create a notebook, we are presented with a page with an empty cell. The cell will have a blue outline, ane the text:\n",
    "\n",
    "    In [ ]: \n",
    "    \n",
    "on the side. The blue outline indicates that we are in *command mode*. There are two modes in Jupyter, command mode and *edit mode*.\n",
    "\n",
    "To enter edit mode simply hit the enter or return key. You will notice that the outline will change to green. In edit mode, with a Python kernel, we can type Python code. Type:\n",
    "\n",
    "    print(\"hello world\")\n",
    "    \n",
    "You will notice that unlike a normal Python REPL, this will note print anything after hitting return again. To *execute* the cell, you need to hold down control and hit enter (``C-Enter``). This will run the code, print the results of the cell and put you back into edit mode.     \n",
    "\n",
    "## Edit Mode\n",
    "\n",
    "To enter *Edit Mode* you need to click on a cell or hit enter when it is surrounded by the blue outline. You will see that it goes green if you are in edit mode. In edit mode you have basic editing functionality. A few keys to know:\n",
    "\n",
    "* Ctr-Enter - Run cell (execute Python code, render Markdown)\n",
    "* ESC - Go back to command mode\n",
    "* TAB - Tab completion\n",
    "* Shift-TAB - Bring up tooltip (ESC to dismiss)\n",
    "\n",
    "\n",
    "## Command Mode\n",
    "\n",
    "*Command Mode* gives to the ability to create, copy, paste, move, and execute cells. A few keys to know:\n",
    "\n",
    "* h - Bring up help (ESC to dismiss)\n",
    "* b - Create cell below\n",
    "* a - Create cell above\n",
    "* c - Copy cell\n",
    "* v - Paste cell below\n",
    "* Enter - Go into Edit Mode\n",
    "* m - Change cell type to Markdown\n",
    "* y - Change cell type to code\n",
    "* ii - Interrupt kernel\n",
    "* oo - Restart kernel\n",
    "\n",
    "## Cell Types\n",
    "\n",
    "* Code\n",
    "* Markdown\n",
    "\n",
    "\n",
    "## Markdown\n",
    "\n",
    "Can make *italicized*, **bold**, and ``monospaced text``:\n",
    "\n",
    "    Can make *italicized*, **bold**, and ``monospaced text``\n",
    "\n",
    "\n",
    "Headers:\n",
    "\n",
    "    # H1\n",
    "    ## H2\n",
    "    ### H3\n",
    " \n",
    "Lists:\n",
    "\n",
    "    * First item\n",
    "    * Second item\n",
    "    \n",
    "Code:\n",
    "\n",
    "    If you indent by four spaces you have code:\n",
    "    \n",
    "        def add(x, y):\n",
    "            return x + yt\n",
    "    \n",
    "## Cell Magic\n",
    "\n",
    "type and run ``%lsmagic`` in a cell.\n",
    "\n",
    "Common magics include:\n",
    "\n",
    "* ``%%time`` - time how long it takes to run cell\n",
    "* ``%%!`` - run shell command\n",
    "* ``%matplotlib inline`` - show matplotlib plots\n",
    "\n",
    "\n",
    "## IPython Help\n",
    "Add ? after function, method, etc for documentation (can also run shift-tab 4 times in notebook). Add ?? after function, method, etc to see the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "pd.__version__, matplotlib.__version__, np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for unicode\n",
    "'\\N{SNAKE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getdefaultencoding() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Intro\n",
    "\n",
    "## Installation\n",
    "\n",
    "Presumably, you have pandas installed if you ran the cell after **Setup** successfully. The Anaconda distribution is a common way to get the Python scientific stack up and running quickly on most platforms. Running ``pip install pandas`` works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has two main datatypes: a Series and a DataFrame\n",
    "# A Series is like a column from a spreadsheet\n",
    "\n",
    "s = pd.Series([0, 4, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A DataFrame is like a spreadsheet\n",
    "\n",
    "df = pd.DataFrame({'name': ['Fred', 'Johh', 'Joe', 'Abe'], 'age': s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do tab completion on objects that exist (shift tab brings up tooltip)\n",
    "# ?? brings up source\n",
    "df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "For this class we will look at some time series data. The class will look at Central Park weather. The assignments will deal with El Nino data.\n",
    "\n",
    "## Central Park\n",
    "\n",
    "\n",
    "https://pastebin.com/vaB6QQGp\n",
    "\n",
    "## El Nino\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/El+Nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# I typically start with imports like this including the matplotlib magic \n",
    "# for most notebooks\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data\n",
    "There are various ``pd.read_`` functions for ingesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary if you started jupyter from the project directory\n",
    "%ls data/\n",
    "# should have central-park-raw.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you execute this cell it will bring up a tooltip due to\n",
    "# the ? at the end. You can also hit shift-tab 4 times\n",
    "# if your cursor is after the v\n",
    "# Hit escape to dismiss the tooltip\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's load the data and treat column 0 as a date\n",
    "nyc = pd.read_csv('data/central-park-raw.csv', parse_dates=[0])\n",
    "# Jupyter will print the result of the last command\n",
    "nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes can get big, so only show the first bit\n",
    "nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data Assignment\n",
    "\n",
    "For your assignment, you will look at El Nino data.\n",
    "\n",
    "The [website](https://archive.ics.uci.edu/ml/datasets/El+Nino)  states:\n",
    "\n",
    "    The data is stored in an ASCII files with one observation per line. Spaces separate fields and periods (.) denote missing values.\n",
    "\n",
    "\n",
    "Load the ``data/tao-all2.dat.gz`` file into a data frame using ``pd.read_csv``.\n",
    "Use the ``names`` variable for the initial column names (taken from website).\n",
    "Replace empty values (``.``) with ``NaN``. Pull the year, month, and date columns into a single variable using the ``parse_dates`` parameter (see the ``pd.read_csv`` docs for info on this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting aside, the columns are actually an Index \n",
    "nyc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If is good to know if columns have a [correct] type, (object could mean string)\n",
    "nyc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also see how much space is taken up\n",
    "nyc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just view the first 10 rows\n",
    "nyc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing the data often makes it easier to view\n",
    "nyc.T  # nyc.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the size (num rows, num cols)\n",
    "nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can inspect the index\n",
    "nyc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the .set_index method to use another column as the index\n",
    "nyc.set_index('EST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo .set_index with .reset_index\n",
    "nyc.set_index('EST').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data Assignment\n",
    "\n",
    "Now it is your turn to inspect the El Nino data.\n",
    " \n",
    "* What are the columns of the dataframe?\n",
    "* What are the types of the columns?\n",
    "* How would you print the first 10 rows of data?\n",
    "* How would you transpose the data?\n",
    "* What is the shape of the data?\n",
    "* How would we inspect the index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak Data\n",
    "\n",
    "  *In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for  prepare data.*\n",
    "  \n",
    "  -@bigdataborat\n",
    "  \n",
    "Let's see how we spend 80% of our time.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like to start by inspecting the columns. Pandas will try to \n",
    "# infer types from CSV files, but doesn't always do the right thing.\n",
    "# Sometimes the data is just messy.\n",
    "nyc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See those spaces in front of some of the Columns?\n",
    "# Remove spaces from front/end of column names\n",
    "nyc.columns = [x.strip() for x in nyc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use underscores to enable attribute access/jupyter completion\n",
    "nyc.columns = [x.replace(' ', '_') for x in nyc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For non-numeric columns, .value_counts gives us \n",
    "# counts of the data. One would think that \n",
    "# PrecipitationIn should be numeric....\n",
    "nyc.PrecipitationIn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There is a \"T\" in there. Trace? \n",
    "# Convert \"T\" to 0.001\n",
    "nyc.PrecipitationIn.replace(\"T\", '0.001')\n",
    "# Convert to numeric data\n",
    "nyc.PrecipitationIn = pd.to_numeric(nyc.PrecipitationIn.replace(\"T\", '0.001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Events.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# can perform string operations on string columns off of the \"str\" attribute\n",
    "nyc.Events.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the type of this column is mixed\n",
    "type(nyc.Events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nyc.Events.apply(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace nan with ''\n",
    "nyc['Events'] = nyc.Events.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nyc.Events.apply(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert inches to cm\n",
    "# If we multiply a column (Series), we are *broadcasting*\n",
    "# the operation to every cell\n",
    "nyc.PrecipitationIn * 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# can also apply an arbitrary function, though this will be slow as it is not vectorized\n",
    "#   map - works with a dictionary (mapping value to new value),  series (like dict), function\n",
    "#   apply - only works with function as a parameter. Allows extra parameters\n",
    "#   aggregate (agg) - works with function or list of functions. If reducing function, returns a scalar.\n",
    "#   transform - wraps agg and won't do a reduction\n",
    "def to_cm(val):\n",
    "    return val * 2.54\n",
    "\n",
    "nyc.PrecipitationIn.transform(to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nyc.PrecipitationIn.map(to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nyc.PrecipitationIn.transform(to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nyc.PrecipitationIn*2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can add and drop columns (axis=1 means along the columns axis)\n",
    "nyc['State'] = 'NYC'\n",
    "nyc = nyc.drop(['State'], axis=1)\n",
    "nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweak Data Assignment\n",
    "* Replace the periods and spaces in the column names with underscores\n",
    "* The temperatures are stored as Celsius. Create a new column, ``air_temp_F``, using Fahrenheit\n",
    "  (Tf = Tc*9/5 + 32)\n",
    "* The wind speed is in meters per second. Create new columns,  adding ``_mph``, that uses miles per hour ( 1 MPS = 2.237 MPH )\n",
    "* Convert the ``date`` column to a date type.\n",
    "* Drop the obs column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Stats\n",
    "\n",
    "A nice feature of pandas is that you can quickly inspect data and get summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe method gives us basic stats. The result is a Data Frame\n",
    "nyc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember transpose\n",
    "nyc.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view non-numeric data pass include='all'\n",
    "nyc.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various aggregation methods (max, mean, median, min, mad, skew, kurtosis, autocorr,\n",
    "#   nunique, sem, std, var)\n",
    "# and properties (hasnans, is_monotonic, is_unique)\n",
    "nyc.Max_Humidity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.quantile(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.quantile([.2,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Mean_Humidity.corr(nyc.Mean_TemperatureF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats Assignment\n",
    "\n",
    "* *Describe* the data\n",
    "* Choose a column\n",
    "  * Print out the max, min, and mean\n",
    "* Correlate (``corr``) the temperature column with the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats Extra\n",
    "* use the ``scatter_matrix`` function in ``pandas.plotting`` to create a correlation matrix (note this might take tens of seconds to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(nino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "Pandas has built-in integration with Matplotlib. Other libraries such as Seaborn also support plotting DataFrames and Series. This is not an in depth intro to Matplotlib, but their website and gallery are great for finding more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# histograms are a quick way to visualize the distribution\n",
    "nyc.Mean_Humidity.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add in figsize=(width,height) to boost size\n",
    "nyc.Mean_Humidity.hist(figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If we use the .plot method we can add title and other attributes\n",
    "nyc.Mean_Humidity.plot(kind='hist', title='Avg Humidity', figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot(x='EST', y='Mean_Humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot(x='EST', y='Mean_Humidity', figsize=(12, 8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can resample columns, since our index is a date we can use *Offset Aliases*\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
    "nyc.set_index('EST').Mean_Humidity.resample('M').mean().plot(figsize=(10, 6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can resample columns, since our index is a date we can use *Offset Aliases*\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
    "nyc.set_index('EST').Mean_Humidity.resample('2W').mean().plot(figsize=(10, 6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the things (may be useful or just art)\n",
    "nyc.set_index('EST').plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot(x='Max_TemperatureF', y='Max_Humidity', kind='scatter', alpha=.5, \n",
    "        figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_TemperatureF.corr(nyc.Max_Humidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Assignment\n",
    "* Plot a histogram of air temp\n",
    "* Plot a scatter plot of latitude and longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we apply a conditional operator to a series we get back a series of True/False values\n",
    "# We call this a \"mask\", which we can use to filter (similar to Photoshop)\n",
    "# all EST in 2000's\n",
    "m2000 = nyc.EST.dt.year >= 2000\n",
    "\n",
    "# below 2010\n",
    "lt2010 = nyc.EST.dt.year < 2010\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"and\" operation looks at whether the operands are truthy or falsey\n",
    "# This is a case where normal Python syntax doesn't work\n",
    "nyc[m2000 and lt2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# & does bitwise comparisons - which is what we want\n",
    "nyc[m2000 & lt2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware if you embed the operations, the bitwise operator binds more tightly to the integers\n",
    "nyc[nyc.EST.dt.year >= 2000 & nyc.EST.dt.year < 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware if you embed the operations, the bitwise operator binds more tightly to the integers\n",
    "nyc[(nyc.EST.dt.year >= 2000) & (nyc.EST.dt.year < 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dec = nyc.EST.dt.month == 12\n",
    "nyc[m_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use loc to filter out based on index value, also takes a boolean index\n",
    "# In fact, you should use .loc instead as a matter of habit (you won't see warnings)\n",
    "nyc.loc[m_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can use loc to filter out based on index value, also takes a boolean index\n",
    "# 2nd option in index op is column names (: to include everything)\n",
    "nyc.loc[m_dec, [x for x in nyc.columns if 'Max' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc note:\n",
    "# can use set_index and sort_index to do quick lookups (if you sort you get quick lookups)\n",
    "nyc.set_index('Events').sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.set_index('Events').sort_index().loc['Fog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use iloc to filter out based on index location (or position)\n",
    "# 2nd option in index op is column indices\n",
    "nyc.iloc[5:10, [2, 5, -2]]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can use iloc to filter out based on index location\n",
    "# 2nd option in index op is column indices\n",
    "nyc.iloc[:, [2, 5, -2]]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.EST.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Assignment\n",
    "* Create a mask, ``m80``, that all years >= 80 and < 90\n",
    "* Create a mask, ``m90``, that all years >= 90 and < 100\n",
    "* Create a mask, ``lon120``, that has all longitudes > 120\n",
    "* Create a mask, ``lat0``, that has latitudes > -2 and < 2\n",
    "* Create a dataframe, ``df80``, that has only those values in ``m80`` and ``lon120`` and ``lat0``\n",
    "* Create a dataframe, ``df90``, that has only those values in ``m90`` and ``lon120`` and ``lat0``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Bonus Assignment\n",
    "* Create a mask, ``m80_2``, that uses a function to filter years >= 80 and < 90\n",
    "* Make sure that ``m80`` is created using operations\n",
    "* Use the ``%time`` *cell magic* to determine which is faster to calculate, ``m80`` or ``m80_2``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find rows that have null data\n",
    "# fish create a mask\n",
    "nyc.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc[nyc.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find columns with null values\n",
    "nyc.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with null values\n",
    "nyc.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = nyc.isnull() \n",
    "nyc[missing_df.Max_TemperatureF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_TemperatureF.fillna(nyc.Max_TemperatureF.mean()).iloc[2219:2222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .interpolate method will do linear interpolation by default\n",
    "nyc.Max_TemperatureF.interpolate().iloc[2219:2222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping rows with missing data\n",
    "nyc.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN Assignment\n",
    "* Find the rows that have null data\n",
    "* Find the columns that have null data\n",
    "* It looks like the ``zon_winds`` has some missing values, use summary stats or plotting to determine how to fill in those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "Pandas allows us to perform aggregates calculations over grouped portions of ``Series`` or ``DataFrames``. The ``.groupby`` method is the low level workhorse that enables this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can group by a column, but if it has unique values it isn't useful\n",
    "nyc.groupby('EST').mean()['CloudCover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get the average cloud cover each month\n",
    "nyc.groupby(nyc.EST.dt.month).mean()['CloudCover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The previous aggregated over every month, \n",
    "# what if we want to group by year and month?\n",
    "nyc.groupby([nyc.EST.dt.year, nyc.EST.dt.month]).mean()['CloudCover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nyc.groupby([nyc.EST.dt.year, nyc.EST.dt.month]).mean(\n",
    ")['CloudCover'].plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With the .agg method we can apply many functions\n",
    "nyc.groupby([nyc.EST.dt.year, nyc.EST.dt.month]).agg(['mean', 'max', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Then plot\n",
    "nyc.groupby([nyc.EST.dt.year, nyc.EST.dt.month]).agg(\n",
    "    ['mean', 'max', 'count'])['Mean_TemperatureF'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Or just look at a table for a column\n",
    "nyc.groupby([nyc.EST.dt.year, nyc.EST.dt.month]).agg(\n",
    "    ['mean', 'max', 'count'])['Max_TemperatureF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Assignment\n",
    "* Find the mean temperature for each year\n",
    "* Find the count of entries for each year\n",
    "* Find the max temperature for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF']).plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can \"unstack\" to pull a left index into a column (0 is the left most index)\n",
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF']).unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can \"unstack\" to pull a left index into a column (1 is the 2nd index)\n",
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF']).unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation\n",
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max],\n",
    "               values=['Mean_TemperatureF']).unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation by year\n",
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max],\n",
    "               values=['Mean_TemperatureF']).unstack(1).plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation by month\n",
    "nyc.pivot_table(index=[nyc.EST.dt.year, nyc.EST.dt.month], aggfunc=[np.max],\n",
    "               values=['Mean_TemperatureF']).unstack(0).plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting Assignment\n",
    "* Pivot the nino data using the ``.pivot_table`` method. Group by year and month, the ``air_temp`` column. Reduce using the ``max``, ``min``, and ``np.mean`` functions. (You will either need to create a month column or use ``year_month_day.dt.month``)\n",
    "* Plot a line plot of the previous pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting Bonus Assignment\n",
    "* Using ``.groupby`` we can sometimes perform the same operation as pivot tables. Pivot the nino data using the ``.groupby`` method. Group by year and month, the ``air_temp_`` column. Reduce using the ``max``, ``min``, and ``np.mean`` functions using ``.groupby``. (Hint: Use the ``.agg`` method on the result of the group by)\n",
    "* Use ``.unstack`` to see the mean ``air_temp_`` by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Pandas allows gives us easy integration with the sklearn library. Let's see if we can \n",
    "predict humidity (``y``) from the other columns (``X``).\n",
    "\n",
    "We will train a Random Forest with a sample of our data, then test it with another sample to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nyc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shift Humidity down to predict next day\n",
    "pd.concat([nyc.Mean_Humidity, nyc.Mean_Humidity.shift(1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression - Try to predict Mean_Humidity (y) from non humidity columns (X)\n",
    "# Get training set (X_train)\n",
    "# Shift Humidity down to predict next day\n",
    "X = nyc[[x for x in nyc.columns if 'Humid' not in x]]\n",
    "y = nyc.Mean_Humidity.shift(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a model \n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make \"Dummy\" variables from Events column\n",
    "nyc_dummy = pd.get_dummies(nyc, columns=['Events'])\n",
    "nyc_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression - Try to predict Mean_Humidity (y) from non humidity columns (X)\n",
    "# Get training set (X_train)\n",
    "X = nyc_dummy[[x for x in nyc_dummy.columns if 'Humid' not in x]]\n",
    "y = nyc_dummy.Mean_Humidity.shift(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a model (whoops data needs to be floats)\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to remove timestamp\n",
    "# Regression - Try to predict Mean_Humidity (y) from non humidity columns (X)\n",
    "# Get training set (X_train)\n",
    "def valid(col):\n",
    "    return 'Humid' not in col and 'EST' not in col\n",
    "X = nyc_dummy[[x for x in nyc_dummy.columns if valid(x)]]\n",
    "y = nyc_dummy.Mean_Humidity.shift(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a model \n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to remove NA\n",
    "# Regression - Try to predict Mean_Humidity (y) from non humidity columns (X)\n",
    "# Get training set (X_train)\n",
    "def valid(col):\n",
    "    return 'Humid' not in col and 'EST' not in col\n",
    "nyc_dummy = nyc_dummy.dropna()\n",
    "X = nyc_dummy[[x for x in nyc_dummy.columns if valid(x)]].iloc[1:]\n",
    "y = nyc_dummy.Mean_Humidity.shift(1).dropna()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a model \n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R2 measure (indicator of accuracy 1 is perfect 0 is horrible)\n",
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.Series(rf_model.predict(X_test)), y_test.reset_index(\n",
    "drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(X.columns, rf_model.feature_importances_),\n",
    "        key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Assignment\n",
    "* Using the nino dataset, see if you can predict what the temperature (``air_temp_F``) will be for the next day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We briefly talked about stacking in the pivot section, here we will\n",
    "# dive in a little more.\n",
    "# Vehicle data - https://www.fueleconomy.gov/feg/download.shtml\n",
    "# Datasets for All Model Years (1984â€“2018)\n",
    "auto = pd.read_csv('https://www.fueleconomy.gov/feg/epadata/vehicles.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auto.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guzzler- if G or T, this vehicle is subject to the gas guzzler tax\n",
    "auto.guzzler.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto.groupby('make').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto.groupby(['year', 'make']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto.groupby(['year', 'make']).size().unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# .stack undoes .unstack\n",
    "auto.groupby(['year', 'make']).size().unstack(1).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# By default .unstack does innermost level (in this case 1)\n",
    "auto.groupby(['year', 'make']).size().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If index has name we can use that\n",
    "auto.groupby(['year', 'make']).size().unstack('make')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If index has name we can use that\n",
    "auto.groupby(['year', 'make']).size().unstack('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Ford through Lexus\n",
    "auto.groupby(['year', 'make']).size().unstack().loc[:,'Ford':'Lexus'].\\\n",
    "plot(figsize=(14,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with parens to allow per line \"flow\" style\n",
    "(\n",
    "auto.groupby(['year', 'make'])\n",
    "    .size()\n",
    "    .unstack('make')\n",
    "    .loc[:,'Ford':'Lexus']\n",
    "    .plot(figsize=(14,10)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just look at Ford, Lexus, & Toyota\n",
    "auto.groupby(['year', 'make']).size().unstack('make').loc[:,['Ford', 'Lexus', 'Toyota']].\\\n",
    "plot(kind='bar', figsize=(14,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average gas mileage per year\n",
    "auto.groupby(['year', 'make'])['city08'].mean().unstack('make').\\\n",
    "loc[:,['Ford', 'BMW', 'Toyota', 'Honda']].\\\n",
    "plot(figsize=(14,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 70% quantile for each mfr\n",
    "auto.groupby(['year', 'make'])['city08'].quantile(.7).unstack('make').\\\n",
    "loc[:,['Ford', 'BMW', 'Toyota', 'Honda']].\\\n",
    "plot(subplots=True, sort_columns=True, figsize=(14,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the drive\n",
    "(\n",
    "auto.groupby(['year', 'make', 'drive'])['city08'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can unstack multiple times\n",
    "(\n",
    "auto.groupby(['year', 'make', 'drive'])['city08'].mean()\n",
    "    .unstack('drive').unstack('make')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Can unstack multiple times\n",
    "(\n",
    "auto.groupby(['year', 'make', 'drive'])['city08'].mean()\n",
    "    .loc[(slice(None), # all years\n",
    "          \"Ford\",    # Ford rows\n",
    "          [\"Rear-Wheel Drive\"])]\n",
    "    .unstack('drive').unstack('year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Can unstack multiple times\n",
    "(\n",
    "auto.groupby(['year', 'make', 'drive'])['city08'].mean()\n",
    "    .loc[(slice(None), # all years\n",
    "          \"Ford\",    # Ford rows\n",
    "          [\"Rear-Wheel Drive\"])]  # if we don't make a list here the index won't have drive\n",
    "    .unstack('drive').unstack('year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simpler may be better\n",
    "(\n",
    "auto.groupby(['year', 'make', 'drive'])['city08'].mean()\n",
    "    .loc[(slice(None), # all years\n",
    "          \"Ford\",    # Ford rows\n",
    "          \"Rear-Wheel Drive\")]\n",
    "    .plot(figsize=(14,10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Assignment\n",
    "\n",
    "* For each Escape (model) in Ford (make) show the by year avg mpg (city08) in tabular form.\n",
    "* Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best mpg for each year/make\n",
    "auto.loc[auto.groupby(['year', 'make']).city08.idxmax()][['year', 'make', 'model', 'city08']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show ford\n",
    "res = auto.loc[auto.groupby(['year', 'make']).city08.idxmax()][['year', 'make', 'model', 'city08']]\n",
    "res[res.make.isin(['Ford'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
